# If you are not sure what all these fields mean, please refer our documentation here:
# https://evalai.readthedocs.io/en/latest/configuration.html

title: 2025-Winter-URP Pedestrian Detection Challenge # 챌린지 제목
short_description: Random number generation challenge for each submission # 간단한 챌린지 설명

# --- #
# 아래 부분들은 챌린지 페이지에서 이 챌린지에 대한 설명을 보여주는 부분입니다. 푸는 사람을 위해 최대한 자세하게 해당 경로에 작성합시다. #
# HTML로 입력해야 보는 사람이 쉽게 읽을 수 있습니다. #
# https://html-online.com/editor/ #
# 위의 사이트 같은 곳에서 작성해서 입력하거나, 직접 잘 입력합시다. #
description: templates/description.html 
evaluation_details: templates/evaluation_details.html
terms_and_conditions: templates/terms_and_conditions.html
image: logo.jpg
submission_guidelines: templates/submission_guidelines.html
leaderboard_description: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras egestas a libero nec sagittis.
# --- #

evaluation_script: evaluation_script.zip # 평가 스크립트

# --- #
# 수정할 필요 없음 #
remote_evaluation: False
is_docker_based: False
# --- #

# --- #
# 시작 날짜와 종료 날짜만 필요하다면 수정 #
start_date: 2025-12-11 00:00:00
end_date: 2099-05-31 23:59:59
published: True
# --- #

# --- #
# 리더보드의 평가 메트릭 관한 부분 #
# 평가 매트릭 이름을 여기서 입력합니다. #
# 평가는 evalutaion_script/main.py에서 작성한 코드로 하고, 리더보드 자체는 맨 아래에서 만듭니다. #
leaderboard:
  - id: 1
    schema:
      {
        "labels": ["MR(all)", "MR(Day)", "MR(Night)", "Recall"],
        "default_order_by": "MR(all)",
        # --- #
        # 리더보드에 설명을 붙이고싶으면 아래와 같이 가능합니다. #
        # 오름차순 내림차순 설정과, 간단한 설명을 리더보드 페이지에 추가할 수 있습니다. #
        "metadata": {
          "MR(all)": {
            "sort_ascending": True,
            "description": "All",
          },
          "MR(Day)": {
            "sort_ascending": True,
            "description": "day",
          },
          "MR(Night)": {
            "sort_ascending": True,
            "description": "night",
          },
          "Recall": {
            "sort_ascending": False,
            "description": "recall",
          }
        }
        # --- #
      }
# --- #

# --- #
# 챌린지 생성하는 부분 #
# 챌린지는 여러개를 생성할 수 있습니다. (id 번호로 구분) #
# 이 설정은 evaluation에도 영향을 미치니 주석을 잘 보고 설정해주세요. #
challenge_phases:
  - id: 1
    name: 2025-Winter-URP Pedestrian Detection Challenge # 챌린지 이름
    description: templates/challenge_phase_1_description.html #챌린지 설명이 들어가는 위치
    leaderboard_public: False # 리더보드 공개 유무

    # --- #
    # 시작-끝 날짜만 필요할 경우 수정 #
    is_public: True
    is_submission_public: True
    start_date: 2023-01-01 00:00:00
    end_date: 2099-05-31 23:59:59
    # --- #

    # --- #
    # 정답 파일(json, csv 등등)의 위치 #
    # annotations폴더에 test.json이 정답이라면, annotations/test.json이라고 입력 #
    # 여기서 입력한 정답 파일은 evalutaion_script/main.py에서 test_annotation_file 파라미터로 들어갑니다. #
    test_annotation_file: annotations/kaist_annotations_test20.json ########정답 파일 수정하기
    # --- #
    
    # --- #
    # evaluation_script/main.py에서 사용하는 구분자 #
    # 챌린지가 여러개라면 이 codename으로 구분하고 아니라면 필요 없습니다. #
    codename: dev
    # --- #

    # --- #
    # 제출 횟수 수정하는 부분 #
    max_submissions_per_day: 100 #하루
    max_submissions_per_month: 1000 #월
    max_submissions: 9999 #전체
    # --- #

    # --- #
    # 수정 할 필요 없음 #
    default_submission_meta_attributes:
      - name: method_name
        is_visible: True
      - name: method_description
        is_visible: True
    is_restricted_to_select_one_submission: False
    is_partial_submission_evaluation_enabled: False
    # --- #

    # --- #
    # 정답 파일로 받을 양식 #
    # 직접 작성한 evaluation 코드에 맞추어 파일 형식을 수정하면 됩니다. #
    allowed_submission_file_types: ".json"
    # --- #

# --- #
# 학습용 데이터셋과 정답 데이터셋의 평가를 분리해서 수행할 수 있습니다. #
# evalutation_script에서 output을 출력할때 trainset과 testset에 대한 output을 함께 반환할 수 있습니다. #
# (evaluation_script/main.py의 test 부분의 output 참조) #
# 정답에 대한 결과만 제공하려면 분리할 필요가 없습니다. #
dataset_splits:
  - id: 1
    name: Test Split
    codename: test_split

# --- #

# --- #
# 리더보드 생성 부분 #
# 리더보드를 여러개 운영해야할 경우에는 수정하고 아닐 경우에는 필요한 하나만 운영해도 괜찮습니다! #
challenge_phase_splits:
  # --- #
  # 생성은 모두 위에서 생성한 것들의 번호를 입력해주면 됩니다. #
  # challenge_phases에서 어떤 챌린지를 쓸지 번호를 입력하고, #
  # leaderboard_id에 위에서 생성한 leaderboard(평가 메트릭 입력했던 부분)의 id를 입력하고, #
  # dataset_split_id을 통해 어떤 데이터셋으로 평가하는지 입력하고, #
  # visibility를 수정하면 끝입니다. #
    # Visibility Description #
    # 1 Only visible to challenge host #
    # 2 Only visible to challenge host and participant who made that submission #
    # 3 Visible to everyone on leaderboard #
  # 공개 옵션은 위의 숫자를 보고 입력 #
  # --- #
  - challenge_phase_id: 1
    leaderboard_id: 1
    dataset_split_id: 1
    visibility: 3
    leaderboard_decimal_precision: 2 # 소수점 자리 설정하는 부분
    is_leaderboard_order_descending: True
  # --- #